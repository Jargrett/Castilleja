library(nlme, lib.loc = "C:/Program Files/R/R-4.1.1/library")
install.packages(c("vegan", "SPECIES"))
install.packages("ggridges")
#Do your housekeeping----------------------
#Set working directory
setwd("C:/Users/jargr/Dropbox/PC/Desktop/Anny Stats/Lab 3")
#Load libraries for this exercise---------
library(car)
library(ggplot2)
library(ggpubr)
#Load data and check---------------------------------
bees<-read.csv("honeybee.csv")
#Check data structure
str(bees)
#Change ppmCaffeine to factor
bees$ppmCaffeine <- as.factor(bees$ppmCaffeine)
#Preliminar data visualization-----------
#Make histogram of response variable (turn in)
hist(bees$consumptionDifferenceFromControl)
#Make boxplots of response~treatment levels (turn in)
boxplot(bees$consumptionDifferenceFromControl~bees$ppmCaffeine)
#Define linear model and check assumptions----------
bm1<-lm(consumptionDifferenceFromControl~ppmCaffeine, data=bees)
#Check assumptions:
#Make qqplot of residuals (turn in)
qqplot(bm1)
#Check homogeneity of variance (turn in)
plot(bm1)
bees$ppmCaffeine#R automatically chooses the first 1 (usually lowest number or alphabetically) as baseline
#the model matrix shows how the effects are defined/calculated
model.matrix(bm1)
#2. anova()
anova(bm1)
#3. summary(aov())
summary(aov(consumptionDifferenceFromControl~ppmCaffeine, data=bees))
#4. Anova() in car package
Anova(bm1)
#Post-hoc comparisons of means (Tukey-HSD)----------
#Note TukeyHSD() only works on aov objects
baov <- (aov(consumptionDifferenceFromControl~ppmCaffeine, data=bees))
TukeyHSD(baov)
#Make a mean and standard error plot ----------------
Beeplot <- ggerrorplot(bees, x = "ppmCaffeine" , y = "consumptionDifferenceFromControl",
desc_stat = "mean_Se", add.params = list(color = "darkgray"),
ylab  = "Consumption different from Control", xlab = "Caffine concentration (ppm)" )
Beeplot
#Make a mean and standard error plot ----------------
Beeplot <- ggerrorplot(bees, x = "ppmCaffeine" , y = "consumptionDifferenceFromControl",
desc_stat = "mean_Se",
ylab  = "Consumption different from Control", xlab = "Caffine concentration (ppm)" )
Beeplot
#Do your housekeeping----------------------
#Set working directory
setwd("C:/Users/jargr/Dropbox/PC/Desktop/Anny Stats/Lab 3")
#Load libraries for this exercise---------
library(car)
library(ggplot2)
#Load data---------------------------------
dragon <- read.csv("C:/Users/jargr/Dropbox/PC/Desktop/Anny Stats/Lab 3/dragons.csv")
View(dragons)
#Set "striped" as baseline manually
dragon$pattern = relevel(dragon$pattern, ref="striped")
#Preliminary visualization-----------------
#Histograms: what do the variable distributions look like
hist(dragon$weight)
#Box plot: understand general pattern, look out for ourliers and heteroscedasticity
boxplot(dragon$weight~dragon$pattern)
#X-Y plot: visualize relationship, make sure linear is reasonable
plot(x = dragon$height, y = dragon$weight)
#Conduct multiple regression---------------
#Some of your past stats classes probably call this an ANCOVA
#Define model (first part defines relationship between variables)
dm1 <- lm(weight~height+pattern, data = dragon )
#Check for violations of assumptions (normality and homoscedasticity)
plot(dm1)
#Basic scatter plot
ggplot(data = dragon, aes(x=height, y=weight, color=pattern))+
geom_point()+
theme_classic()
#The safest way to add your fit lines is to use predicted values
#Do not rely on "reg.line" or "geom_smooth with lm"
#Add predicted values to data (fitted fits our model to data)
dragon$pred.weight<-fitted(dm1)
#Try plotting again, add lines using predicted values
ggplot(data = dragon, aes(x=height, y=weight, color=pattern))+
geom_point()+
geom_line(aes(x=height, y=pred.weight, color=pattern))+ #make sure to specify that lines are plotted with predicted weight
theme_classic()
#How to make this plot better?
#How to make this plot better?
#Hint: units? colors? point sizes and shapes?
#Do your housekeeping----------------------
#Set working directory
setwd("C:/Users/jargr/Dropbox/PC/Desktop/Anny Stats/Lab 3")
#Load libraries for this exercise---------
library(car)
library(ggplot2)
library(ggpubr)
#Load data and check---------------------------------
bees<-read.csv("honeybee.csv")
#Check data structure
str(bees)
#Change ppmCaffeine to factor
bees$ppmCaffeine <- as.factor(bees$ppmCaffeine)
#Preliminar data visualization-----------
#Make histogram of response variable (turn in)
hist(bees$consumptionDifferenceFromControl)
#Make boxplots of response~treatment levels (turn in)
boxplot(bees$consumptionDifferenceFromControl~bees$ppmCaffeine)
#Check assumptions:
#Make qqplot of residuals (turn in)
qqplot(bm1)
#Define linear model and check assumptions----------
bm1<-lm(consumptionDifferenceFromControl~ppmCaffeine, data=bees)
#Check assumptions:
#Make qqplot of residuals (turn in)
qqplot(bm1)
#Make boxplots of response~treatment levels (turn in)
boxplot(bees$consumptionDifferenceFromControl~bees$ppmCaffeine)
#Define linear model and check assumptions----------
bm1<-lm(consumptionDifferenceFromControl~ppmCaffeine, data=bees)
#Check assumptions:
#Make qqplot of residuals (turn in)
qqplot(bm1)
#Check homogeneity of variance (turn in)
plot(bm1)
bees$ppmCaffeine#R automatically chooses the first 1 (usually lowest number or alphabetically) as baseline
#the model matrix shows how the effects are defined/calculated
model.matrix(bm1)
#Check homogeneity of variance (turn in)
plot(bm1)
ylab  = "Consumption different from Control", xlab = "Caffine concentration (ppm)" )
#Make a mean and standard error plot ----------------
Beeplot <- ggerrorplot(bees, x = "ppmCaffeine" , y = "consumptionDifferenceFromControl",
desc_stat = "mean_Se", add.params = list(color = "darkgray"),
ylab  = "Consumption different from Control", xlab = "Caffine concentration (ppm)" )
Beeplot
